{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a13929",
   "metadata": {},
   "source": [
    "NLTK POS Tags Examples are as below:\n",
    "\n",
    "https://www.nltk.org/api/nltk.tag.html\n",
    "\n",
    "Abbreviation    Meaning\n",
    "\n",
    "CC  coordinating conjunction <br />\n",
    "CD  cardinal digit <br />\n",
    "DT  determiner<br />\n",
    "EX  existential there <br />\n",
    "FW  foreign word <br />\n",
    "IN  preposition/subordinating conjunction <br />\n",
    "JJ  This NLTK POS Tag is an adjective (large)<br />\n",
    "JJR adjective, comparative (larger)<br />\n",
    "JJS adjective, superlative (largest)<br />\n",
    "LS  list market<br />\n",
    "MD  modal (could, will)<br />\n",
    "NN  noun, singular (cat, tree)<br />\n",
    "NNS noun plural (desks)<br />\n",
    "NNP proper noun, singular (sarah) <br />\n",
    "NNPS    proper noun, plural (indians or americans) <br />\n",
    "PDT predeterminer (all, both, half)<br />\n",
    "POS possessive ending (parent\\ ‘s) <br />\n",
    "PRP personal pronoun (hers, herself, him, himself)<br />\n",
    "PRP$    possessive pronoun (her, his, mine, my, our )<br />\n",
    "RB  adverb (occasionally, swiftly)<br />\n",
    "RBR adverb, comparative (greater)<br />\n",
    "RBS adverb, superlative (biggest)<br />\n",
    "RP  particle (about)<br />\n",
    "TO  infinite marker (to)<br />\n",
    "UH  interjection (goodbye)<br />\n",
    "VB  verb (ask)<br />\n",
    "VBG verb gerund (judging)<br />\n",
    "VBD verb past tense (pleaded)<br />\n",
    "VBN verb past participle (reunified)<br />\n",
    "VBP verb, present tense not 3rd person singular(wrap)<br />\n",
    "VBZ verb, present tense with 3rd person singular (bases)<br />\n",
    "WDT wh-determiner (that, what)<br />\n",
    "WP  wh- pronoun (who)<br />\n",
    "WRB wh- adverb (how)<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32adf6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\miqut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk #etiquetador medio\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d365a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b71ceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('lost', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('found', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('park', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is the lost dog I found at the park\".split()\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d55c29",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93muniversal_tagset\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('universal_tagset')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/universal_tagset/en-ptb.map\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\miqut/nltk_data'\n    - 'C:\\\\tools\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\tools\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\tools\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\miqut\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15908/3864977409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'universal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m    165\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Maps to the specified tagset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 tagged_tokens = [\n\u001b[0m\u001b[0;32m    127\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en-ptb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 tagged_tokens = [\n\u001b[1;32m--> 127\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en-ptb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 ]\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\mapping.py\u001b[0m in \u001b[0;36mmap_tag\u001b[1;34m(source, target, source_tag)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"en-brown\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagset_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_tag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\mapping.py\u001b[0m in \u001b[0;36mtagset_mapping\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_MAPPINGS\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_MAPPINGS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"universal\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0m_load_universal_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Added the new Russian National Corpus mappings because the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# Russian model for nltk.pos_tag() uses it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\mapping.py\u001b[0m in \u001b[0;36m_load_universal_map\u001b[1;34m(fileid)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_load_universal_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_UNIVERSAL_DATA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".map\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# When mapping to the Universal Tagset,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93muniversal_tagset\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('universal_tagset')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/universal_tagset/en-ptb.map\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\miqut/nltk_data'\n    - 'C:\\\\tools\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\tools\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\tools\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\miqut\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(text, tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6685689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'NN'), ('is', 'NN'), ('the', 'NN'), ('lost', 'NN'), ('dog', 'NN'), ('I', 'NN'), ('found', 'NN'), ('at', 'NN'), ('the', 'NN'), ('park', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "defaultTagger = nltk.DefaultTagger(\"NN\")\n",
    "print(defaultTagger.tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d42acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\miqut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\cess_esp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"cess_esp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33931a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\miqut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b041047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\miqut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be21a1b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Currently, NLTK pos_tag only supports English and Russian (i.e. lang='eng' or lang='rus')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15908/4194588252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtexto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Hola Caracola caminar caminaré camino caminaría en autobus\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'spa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m    165\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m# Currently only supports English and Russian.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rus\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         raise NotImplementedError(\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[1;34m\"Currently, NLTK pos_tag only supports English and Russian \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;34m\"(i.e. lang='eng' or lang='rus')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Currently, NLTK pos_tag only supports English and Russian (i.e. lang='eng' or lang='rus')"
     ]
    }
   ],
   "source": [
    "texto = \"Hola Caracola caminar caminaré camino caminaría en autobus\".split()\n",
    "nltk.pos_tag(texto, lang='spa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c31260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hola', 'NOUN'), ('Caracola', 'NOUN'), ('ir', 'VERB'), ('a', 'DET'), ('correr', 'NOUN'), ('en', 'ADP'), ('autobus', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "texto = \"Hola Caracola ir a correr en autobus\".split()\n",
    "print(nltk.pos_tag(texto, tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "618b1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cess_esp as cess\n",
    "from nltk import UnigramTagger as ut\n",
    "\n",
    "# Read the corpus\n",
    "cess_sents = cess.tagged_sents()\n",
    "\n",
    "# Train\n",
    "uni_tag = ut(cess_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b7abde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hola', None), (',', 'Fc'), ('esta', 'dd0fs0'), ('concha', None), ('está', 'vmip3s0'), ('fria', None), ('.', 'Fp')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hola , esta concha está fria .\"\n",
    "print(uni_tag.tag(sentence.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59310976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bones,', None), ('aquesta', None), ('petxina', None), ('està', None), ('freda', None), ('.', 'Fp')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Bones, aquesta petxina està freda .\"\n",
    "print(uni_tag.tag(sentence.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6d220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Existen más \"etiquetadores\" como UnigramTagger?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9228603",
   "metadata": {},
   "source": [
    "### Activity:\n",
    "\n",
    "From all these amazon reviews, we want to obtain ALL the ADJECTIVES with a rating b >4 ratings stars, and <2 stars.\n",
    "\n",
    "https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda91e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_ratings = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b995881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284954"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodReviews = all_ratings[all_ratings.Rating >= 4].Reviews\n",
    "goodReviews.head()\n",
    "#goodReviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16fe1d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     I already had a phone with problems... I know ...\n",
       "13    I'm really disappointed about my phone and ser...\n",
       "22    I purchased this phone in December as a christ...\n",
       "28         was not in good condition but does work good\n",
       "29    Just... not good. The phone has great screen r...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badReviws = all_ratings[all_ratings.Rating < 2].Reviews\n",
    "badReviws.head()\n",
    "#badReviws.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af386f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ceea8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCleaner(text):\n",
    "  return str(text).lower()\n",
    "  #return re.sub(r'\\W+', \" \", str(text)).lower().trim()\n",
    "\n",
    "def getAdjectives(reviews):\n",
    "  adjectives = {}\n",
    "  for review in reviews[1:1000]:\n",
    "    cleanText = wordCleaner(review)\n",
    "    tokens = word_tokenize(cleanText)\n",
    "    taggedTokens = pos_tag(tokens)\n",
    "    for taggedToken in taggedTokens:\n",
    "      (word, tokenType) = taggedToken\n",
    "      if tokenType == \"JJ\":\n",
    "        if word in adjectives:\n",
    "          adjectives[word] = adjectives[word] + 1\n",
    "        else:\n",
    "          adjectives[word] = 1\n",
    "  return adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3e172c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "maybeGoodAdjectives = getAdjectives(goodReviews)\n",
    "maybeBadAdjectives = getAdjectives(badReviws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e8cb416c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 275),\n",
       " ('great', 273),\n",
       " ('nice', 98),\n",
       " ('easy', 90),\n",
       " ('other', 89),\n",
       " ('excellent', 79),\n",
       " ('clear', 75),\n",
       " ('dual', 70),\n",
       " ('unlocked', 67),\n",
       " ('android', 63),\n",
       " ('sim', 57),\n",
       " ('big', 51),\n",
       " ('same', 45),\n",
       " ('many', 43)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(maybeGoodAdjectives.items(), key=lambda item: item[1], reverse=True)[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0833fd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 134),\n",
       " ('new', 117),\n",
       " ('bad', 81),\n",
       " ('unlocked', 74),\n",
       " ('other', 59),\n",
       " ('great', 51),\n",
       " ('able', 49),\n",
       " ('slow', 43),\n",
       " ('sim', 41),\n",
       " ('t-mobile', 36),\n",
       " ('first', 35),\n",
       " ('old', 34),\n",
       " ('screen', 32),\n",
       " ('terrible', 32)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(maybeBadAdjectives.items(), key=lambda item: item[1], reverse=True)[1:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73047ae",
   "metadata": {},
   "source": [
    "En las reviews negativas la palabra más usada es \"good\" que por si sola es un adjetivo positivo. En estos casos lo más probable es que el adjetivo se encuentre negado, como por ejemplo: \"not in good\"."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a707b6ce8c685eb936424fcc3009d4b4b7a52543c4db09380a3fc49186ceb509"
  },
  "kernelspec": {
   "display_name": "MyPy397",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
